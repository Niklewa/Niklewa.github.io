---
title: "Papers"
theme: "jekyll-theme-minimal"
layout: default
---
<head>


<meta name="viewport" content="width=device-width, initial-scale=1">
<meta charset="utf-8">
  
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<style>  
.footer {  
position: fixed;  
margin: 0 auto;
left: 10px;  
bottom: 5px;  
right: 10px;   
max-width: auto;  
background-color: whitesmoke;  
color: grey;  
text-align: center;  
}  

img {  
    max-width: 200px; 
    float: left; 
    margin-right: 10px; 
  } 
  
  
  
div.content { max-width: 800px;
              margin: auto}



@media screen and (min-width: 600px) {
  div.example {
    max-width: auto;
  }
}

</style>



</head>

&nbsp; <br>
&nbsp; <br>
&nbsp; <br>

<p align="justify" style="font-size:16px"> In this section you can find some of my research writings. </p>

&nbsp; <br>
&nbsp; <br>

### My bachelor's thesis - Philosophical Challenges to Imprecise Probabilism

<p align="justify" style="font-size:14px">
&nbsp; In this work, I introduce the concept of Imprecise Probabilism, a notion where intervals are utilized to represent an agent's beliefs instead of single values. I provide arguments both in favor of and against this approach, with a particular emphasis on the accuracy centered approach to epistemology. While imprecise probabilities find support in numerous evidential claims, they also encounter challenges from a more theoretical perspective, such as the accuracy-centered epistemology.</p>

- <a href="https://github.com/Niklewa/Niklewa.github.io/raw/main/NLewandowskiBA.pdf">Bachelor's thesis</a>

&nbsp; <br>

### My master's thesis -  Exploring the Maximally Sensitive Priors 

<p align="justify" style="font-size:14px">
&nbsp; In this work we explore the Maximum Sensitivity method (MaxSen) of selecting priors for Bayesian inference in the face of severe lack of evidence (Konek, 2013). The most popular and well-respected principle of dealing with uncertainty in such contexts is the Maximum Entropy principle (MaxEnt), which, roughly, recommends the least informative prior in a given situation. MaxSen, instead, minimizes the need of relying on the epistemic luck of true parameter values (such as chances) falling closely to their prior estimate. We start with a brief outline of MaxEnt and an explanation of Konekâ€™s anti-luck approach to priors. Next, we explore his perspective on the theoretical role of priors and illustrate how this viewpoint informs the formulation of MaxSen. Then we explore the impact of the choice of the scoring method on the recommendations made by MaxSen. It turns out that if we use Kullback-Leibler Divergence (KLD) as a distance measure (instead of Cramer-von-Mises, which Konek originally used), the recommendations are the same as that of MaxEnt. Next, we estimate how quickly the recommended prior distribution concentration increases with the planned sample size. </p>

- <a href="https://github.com/Niklewa/Niklewa.github.io/raw/main/NLewandowskiMA.pdf">Master's thesis</a>

&nbsp; <br>
&nbsp; <br>
&nbsp; <br>
&nbsp; <br>
&nbsp; <br>
&nbsp; <br>

<div class="footer">  
<center>

<p style="text-align:center;font-size:14px">Nikodem Lewandowski</p>  
&nbsp; &nbsp; <a href=mailto:"nikodemlewandowski@gmail.com/"><i class="fa fa-envelope" style="font-size:18px;color:grey"></i></a> &nbsp; &nbsp;
<a href="https://github.com/Niklewa"><i class="fa fa-github" style="font-size:18px;color:grey"></i></a> &nbsp; &nbsp;
<a href="https://www.linkedin.com/in/nikodem-lewandowski-96b482244/"><i class="fa fa-linkedin-square" style="font-size:18px;color:grey"></i></a> &nbsp; &nbsp;
<a href="https://www.facebook.com/nikodem.lewandowski.754"><i class="fa fa-facebook-f" style="font-size:18px;color:grey"></i></a> &nbsp; &nbsp;

 
</center>
</div>  